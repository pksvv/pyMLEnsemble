{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem : What should be my saving target to buy laptop?\n",
    "\n",
    "* You - $1000$\n",
    "* Sameer - $900$\n",
    "* Nitika - $950$\n",
    "* Roshan - $1050$\n",
    "* Srikanth - $1500\n",
    "\n",
    "Decide to average out - Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1000+900+950+1050+1500)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>loan_duration_mo</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>payment_pcnt_income</th>\n",
       "      <th>time_in_residence</th>\n",
       "      <th>age_yrs</th>\n",
       "      <th>number_loans</th>\n",
       "      <th>dependents</th>\n",
       "      <th>bad_credit</th>\n",
       "      <th>checking_account_status_0 - 200 DM</th>\n",
       "      <th>...</th>\n",
       "      <th>home_ownership_own</th>\n",
       "      <th>home_ownership_rent</th>\n",
       "      <th>job_category_highly skilled</th>\n",
       "      <th>job_category_skilled</th>\n",
       "      <th>job_category_unemployed-unskilled-non-resident</th>\n",
       "      <th>job_category_unskilled-resident</th>\n",
       "      <th>telephone_none</th>\n",
       "      <th>telephone_yes</th>\n",
       "      <th>foreign_worker_no</th>\n",
       "      <th>foreign_worker_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1122334</td>\n",
       "      <td>6</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6156361</td>\n",
       "      <td>48</td>\n",
       "      <td>5951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2051359</td>\n",
       "      <td>12</td>\n",
       "      <td>2096</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8740590</td>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3924540</td>\n",
       "      <td>24</td>\n",
       "      <td>4870</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  loan_duration_mo  loan_amount  payment_pcnt_income  \\\n",
       "0      1122334                 6         1169                    4   \n",
       "1      6156361                48         5951                    2   \n",
       "2      2051359                12         2096                    2   \n",
       "3      8740590                42         7882                    2   \n",
       "4      3924540                24         4870                    3   \n",
       "\n",
       "   time_in_residence  age_yrs  number_loans  dependents  bad_credit  \\\n",
       "0                  4       67             2           1           0   \n",
       "1                  2       22             1           1           1   \n",
       "2                  3       49             1           2           0   \n",
       "3                  4       45             1           2           0   \n",
       "4                  4       53             2           2           1   \n",
       "\n",
       "   checking_account_status_0 - 200 DM  ...  home_ownership_own  \\\n",
       "0                                   0  ...                   1   \n",
       "1                                   1  ...                   1   \n",
       "2                                   0  ...                   1   \n",
       "3                                   0  ...                   0   \n",
       "4                                   0  ...                   0   \n",
       "\n",
       "   home_ownership_rent  job_category_highly skilled  job_category_skilled  \\\n",
       "0                    0                            0                     1   \n",
       "1                    0                            0                     1   \n",
       "2                    0                            0                     0   \n",
       "3                    0                            0                     1   \n",
       "4                    0                            0                     1   \n",
       "\n",
       "   job_category_unemployed-unskilled-non-resident  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   job_category_unskilled-resident  telephone_none  telephone_yes  \\\n",
       "0                                0               0              1   \n",
       "1                                0               1              0   \n",
       "2                                1               1              0   \n",
       "3                                0               1              0   \n",
       "4                                0               1              0   \n",
       "\n",
       "   foreign_worker_no  foreign_worker_yes  \n",
       "0                  0                   1  \n",
       "1                  0                   1  \n",
       "2                  0                   1  \n",
       "3                  0                   1  \n",
       "4                  0                   1  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('credit_preped.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 63 columns):\n",
      "customer_id                                               1000 non-null int64\n",
      "loan_duration_mo                                          1000 non-null int64\n",
      "loan_amount                                               1000 non-null int64\n",
      "payment_pcnt_income                                       1000 non-null int64\n",
      "time_in_residence                                         1000 non-null int64\n",
      "age_yrs                                                   1000 non-null int64\n",
      "number_loans                                              1000 non-null int64\n",
      "dependents                                                1000 non-null int64\n",
      "bad_credit                                                1000 non-null int64\n",
      "checking_account_status_0 - 200 DM                        1000 non-null int64\n",
      "checking_account_status_< 0 DM                            1000 non-null int64\n",
      "checking_account_status_> 200 DM or salary assignment     1000 non-null int64\n",
      "checking_account_status_none                              1000 non-null int64\n",
      "credit_history_all loans at bank paid                     1000 non-null int64\n",
      "credit_history_critical account - other non-bank loans    1000 non-null int64\n",
      "credit_history_current loans paid                         1000 non-null int64\n",
      "credit_history_no credit - paid                           1000 non-null int64\n",
      "credit_history_past payment delays                        1000 non-null int64\n",
      "purpose_business                                          1000 non-null int64\n",
      "purpose_car (new)                                         1000 non-null int64\n",
      "purpose_car (used)                                        1000 non-null int64\n",
      "purpose_domestic appliances                               1000 non-null int64\n",
      "purpose_education                                         1000 non-null int64\n",
      "purpose_furniture/equipment                               1000 non-null int64\n",
      "purpose_other                                             1000 non-null int64\n",
      "purpose_radio/television                                  1000 non-null int64\n",
      "purpose_repairs                                           1000 non-null int64\n",
      "purpose_retraining                                        1000 non-null int64\n",
      "savings_account_balance_100 - 500 DM                      1000 non-null int64\n",
      "savings_account_balance_500 - 1000 DM                     1000 non-null int64\n",
      "savings_account_balance_< 100 DM                          1000 non-null int64\n",
      "savings_account_balance_>= 1000 DM                        1000 non-null int64\n",
      "savings_account_balance_unknown/none                      1000 non-null int64\n",
      "time_employed_yrs_1 - 4 years                             1000 non-null int64\n",
      "time_employed_yrs_4 - 7 years                             1000 non-null int64\n",
      "time_employed_yrs_< 1 year                                1000 non-null int64\n",
      "time_employed_yrs_>= 7 years                              1000 non-null int64\n",
      "time_employed_yrs_unemployed                              1000 non-null int64\n",
      "gender_status_female-divorced/separated/married           1000 non-null int64\n",
      "gender_status_male-divorced/separated                     1000 non-null int64\n",
      "gender_status_male-married/widowed                        1000 non-null int64\n",
      "gender_status_male-single                                 1000 non-null int64\n",
      "other_signators_co-applicant                              1000 non-null int64\n",
      "other_signators_guarantor                                 1000 non-null int64\n",
      "other_signators_none                                      1000 non-null int64\n",
      "property_building society savings/life insurance          1000 non-null int64\n",
      "property_car or other                                     1000 non-null int64\n",
      "property_real estate                                      1000 non-null int64\n",
      "property_unknown-none                                     1000 non-null int64\n",
      "other_credit_outstanding_bank                             1000 non-null int64\n",
      "other_credit_outstanding_none                             1000 non-null int64\n",
      "other_credit_outstanding_stores                           1000 non-null int64\n",
      "home_ownership_for free                                   1000 non-null int64\n",
      "home_ownership_own                                        1000 non-null int64\n",
      "home_ownership_rent                                       1000 non-null int64\n",
      "job_category_highly skilled                               1000 non-null int64\n",
      "job_category_skilled                                      1000 non-null int64\n",
      "job_category_unemployed-unskilled-non-resident            1000 non-null int64\n",
      "job_category_unskilled-resident                           1000 non-null int64\n",
      "telephone_none                                            1000 non-null int64\n",
      "telephone_yes                                             1000 non-null int64\n",
      "foreign_worker_no                                         1000 non-null int64\n",
      "foreign_worker_yes                                        1000 non-null int64\n",
      "dtypes: int64(63)\n",
      "memory usage: 492.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll look at Ensembling for both classification (bad_credit) and regression (age_yrs)\n",
    "\n",
    "Dropping customer id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('customer_id',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by training individual models\n",
    "\n",
    "### For classification following models will be used:\n",
    "\n",
    "* SVC - Support vector classifier\n",
    "* Logistic Reg\n",
    "* KNN classifier\n",
    "\n",
    "### For regression following models will be used:\n",
    "\n",
    "* SVR - Support vector regressor\n",
    "* Linear Reg\n",
    "* KNN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "# Classification models\n",
    "\n",
    "rand_seed = 42\n",
    "np.random.seed=rand_seed\n",
    "\n",
    "log_cf = LogisticRegression(solver='lbfgs',random_state=rand_seed)\n",
    "svc_cf = SVC(gamma='scale',random_state=rand_seed)\n",
    "knn_cf = KNeighborsClassifier()\n",
    "\n",
    "clf = [log_cf,svc_cf,knn_cf]\n",
    "\n",
    "# Regression models\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "svr_reg = SVR(gamma='scale')\n",
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "\n",
    "reg = [linear_reg,svr_reg,knn_reg]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Standardize data, Split data into training/testing sets, get accuracy metrices, and train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Standardize data\n",
    "\n",
    "def standdata(df):\n",
    "    scaler=RobustScaler()\n",
    "    data=scaler.fit_transform(df)\n",
    "    return data\n",
    "\n",
    "# 2 - Split data into training/testing sets\n",
    "def split_data(features,target_name=None):\n",
    "    # get target column\n",
    "    target = features[target_name]\n",
    "    # Drop target value from data\n",
    "    temp_data = features.drop(target_name,axis=1)\n",
    "    temp_data = standdata(temp_data)\n",
    "    \n",
    "    # split\n",
    "    x_train,x_val,y_train,y_val = train_test_split(temp_data,target,test_size=0.1)\n",
    "    \n",
    "    return (x_train,x_val,y_train,y_val)\n",
    "\n",
    "# 3 - get accuracy metrics \n",
    "def get_reg(pred,actual):\n",
    "    mae = mean_absolute_error(actual,pred)\n",
    "    mse = mean_squared_error(actual,pred)\n",
    "    return mae#, mse\n",
    "\n",
    "def get_acc(pred,actual):\n",
    "    return accuracy_score(actual,pred)*100\n",
    "\n",
    "# 4 - Training the model\n",
    "\n",
    "def train_model(model,features=None,target_name=None,nfolds=10,task='class'):\n",
    "    # Getting target column\n",
    "    target = features[target_name]\n",
    "    # Dropping target\n",
    "    temp = features.drop(target_name,axis=1)\n",
    "    temp = standdata(temp)\n",
    "    \n",
    "    if task=='reg':\n",
    "        score = -1 * cross_val_score(model,temp,target,scoring='neg_mean_absolute_error')\n",
    "        print(f'\\n Mean absolute error of {model} : {round(score[0],4)}')\n",
    "        print('______________________________________\\n\\n')\n",
    "    else:\n",
    "        score = cross_val_score(model,temp,target,cv=nfolds,scoring='accuracy')\n",
    "        print(f'Accuracy of {model} is {score[0]*100}%')\n",
    "        print('______________________________________\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) is 82.0%\n",
      "______________________________________\n",
      "\n",
      "\n",
      "Accuracy of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) is 83.0%\n",
      "______________________________________\n",
      "\n",
      "\n",
      "Accuracy of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform') is 74.0%\n",
      "______________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in clf:\n",
    "    train_model(model,features=df,target_name='bad_credit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean absolute error of LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) : 7.6008\n",
      "______________________________________\n",
      "\n",
      "\n",
      "\n",
      " Mean absolute error of SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) : 7.9741\n",
      "______________________________________\n",
      "\n",
      "\n",
      "\n",
      " Mean absolute error of KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform') : 8.0677\n",
      "______________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in reg:\n",
    "    train_model(model,features=df,target_name='age_yrs',task='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Ensemble Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val = split_data(df,target_name='age_yrs')\n",
    "\n",
    "# fit base models\n",
    "linear_reg.fit(x_train,y_train)\n",
    "knn_reg.fit(x_train,y_train)\n",
    "svr_reg.fit(x_train,y_train)\n",
    "\n",
    "# make predictions\n",
    "pred1 = linear_reg.predict(x_val)\n",
    "pred2 = knn_reg.predict(x_val)\n",
    "pred3 = svr_reg.predict(x_val)\n",
    "\n",
    "average_pred = (pred1+pred2+pred3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model\n",
      "7.00939453125\n",
      "\n",
      "KNN Regression model\n",
      "6.438000000000001\n",
      "\n",
      "SVR Regression model\n",
      "6.587693389526012\n",
      "\n",
      "Average Model\n",
      "6.450679066094097\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression model')\n",
    "print(get_reg(pred1,y_val))\n",
    "print()\n",
    "print('KNN Regression model')\n",
    "print(get_reg(pred2,y_val))\n",
    "print()\n",
    "print('SVR Regression model')\n",
    "print(get_reg(pred3,y_val))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Average Model')\n",
    "print(get_reg(average_pred,y_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Average \n",
    "\n",
    "**Intuition** : Models with higher predictive powers should be given higher weights as compared to those with lower accuracy.\n",
    "\n",
    "Weights are numbers between 0 and 1 totalling to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model\n",
      "7.00939453125\n",
      "\n",
      "KNN Regression model\n",
      "6.438000000000001\n",
      "\n",
      "SVR Regression model\n",
      "6.587693389526012\n",
      "\n",
      "Weighted Average Model\n",
      "6.498042413788097\n"
     ]
    }
   ],
   "source": [
    "linear_reg.fit(x_train,y_train)  # 0.25\n",
    "knn_reg.fit(x_train,y_train)     # 0.25\n",
    "svr_reg.fit(x_train,y_train)     # 0.5\n",
    "\n",
    "pred1 = linear_reg.predict(x_val)\n",
    "pred2 = knn_reg.predict(x_val)\n",
    "pred3 = svr_reg.predict(x_val)\n",
    "\n",
    "\n",
    "# Performing weighted average\n",
    "w_avg = (0.15*pred1 + 0.15*pred2 + 0.7*pred3)\n",
    "\n",
    "print('Linear Regression model')\n",
    "print(get_reg(pred1,y_val))\n",
    "print()\n",
    "print('KNN Regression model')\n",
    "print(get_reg(pred2,y_val))\n",
    "print()\n",
    "print('SVR Regression model')\n",
    "print(get_reg(pred3,y_val))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Weighted Average Model')\n",
    "print(get_reg(w_avg,y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max / Majority Voting\n",
    "\n",
    "Max voting is similar to averaging but it applies to classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model\n",
      "74.0\n",
      "KNN Model\n",
      "79.0\n",
      "Support Vector Classifier Model\n",
      "78.0\n",
      "Max Voting Model\n",
      "78.0\n"
     ]
    }
   ],
   "source": [
    "x_train,x_val,y_train,y_val = split_data(df,target_name='bad_credit')\n",
    "\n",
    "# fitting classification models\n",
    "log_cf.fit(x_train,y_train)\n",
    "knn_cf.fit(x_train,y_train)\n",
    "svc_cf.fit(x_train,y_train)\n",
    "\n",
    "# Predictions\n",
    "pred1=log_cf.predict(x_val)\n",
    "pred2=knn_cf.predict(x_val)\n",
    "pred3=svc_cf.predict(x_val)\n",
    "\n",
    "# maxvoting list\n",
    "\n",
    "maxvote_pred = []\n",
    "\n",
    "for i in range(0,len(x_val)):\n",
    "    maxvote_pred.append(mode([pred1[i],pred3[i],pred3[i]]))\n",
    "    \n",
    "print('Logistic Regression Model')\n",
    "print(get_acc(pred1,y_val))\n",
    "\n",
    "print('KNN Model')\n",
    "print(get_acc(pred2,y_val))\n",
    "\n",
    "print('Support Vector Classifier Model')\n",
    "print(get_acc(pred3,y_val))\n",
    "\n",
    "print('Max Voting Model')\n",
    "print(get_acc(np.array(maxvote_pred),y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max voting using sklearn.ensemble.VotingClassifier\n",
      "78.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "max_model=VotingClassifier(estimators=[('Logistic',log_cf),('knn',knn_cf),('svc',svc_cf)],voting='hard')\n",
    "\n",
    "max_model.fit(x_train,y_train)\n",
    "\n",
    "print('Max voting using sklearn.ensemble.VotingClassifier')\n",
    "print(get_acc(max_model.predict(x_val),y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Techniques such as Boosting, Stacking, Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor,BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier\n",
    "\n",
    "# Reg Models\n",
    "rf_reg = RandomForestRegressor(n_estimators=100,random_state=rand_seed)\n",
    "ex_reg = ExtraTreesRegressor(n_estimators=100,random_state=rand_seed)\n",
    "bag_reg = BaggingRegressor(svr_reg,n_estimators=10,random_state=rand_seed)\n",
    "\n",
    "# Clf Models\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,random_state=rand_seed)\n",
    "ex_clf = ExtraTreesClassifier(n_estimators=100,random_state=rand_seed)\n",
    "bag_clf = BaggingClassifier(svc_cf,n_estimators=10,random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Random Forest Regressor :  6.8039\n",
      "MAE Extra Trees Regressor :  7.713900000000001\n",
      "MAE Bagging Meta Regressor :  6.39210422863734\n"
     ]
    }
   ],
   "source": [
    "x_train,x_val,y_train,y_val = split_data(df,target_name='age_yrs')\n",
    "\n",
    "rf_reg.fit(x_train,y_train)\n",
    "ex_reg.fit(x_train,y_train)\n",
    "bag_reg.fit(x_train,y_train)\n",
    "\n",
    "print('MAE Random Forest Regressor : ',get_reg(rf_reg.predict(x_val),y_val))\n",
    "print('MAE Extra Trees Regressor : ',get_reg(ex_reg.predict(x_val),y_val))\n",
    "print('MAE Bagging Meta Regressor : ',get_reg(bag_reg.predict(x_val),y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Random Forest Classifier :  73.0\n",
      "Accuracy Score for Extra Tree Classifier :  72.0\n",
      "Accuracy Score for Bagging Meta Classifier :  74.0\n"
     ]
    }
   ],
   "source": [
    "x_train,x_val,y_train,y_val = split_data(df,target_name='bad_credit')\n",
    "\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ex_clf.fit(x_train,y_train)\n",
    "bag_clf.fit(x_train,y_train)\n",
    "\n",
    "# print accuracy score for each classifier\n",
    "\n",
    "print('Accuracy Score for Random Forest Classifier : ',get_acc(rf_clf.predict(x_val),y_val))\n",
    "print('Accuracy Score for Extra Tree Classifier : ',get_acc(ex_clf.predict(x_val),y_val))\n",
    "print('Accuracy Score for Bagging Meta Classifier : ',get_acc(bag_clf.predict(x_val),y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\n",
    "\n",
    "ada_reg = AdaBoostRegressor(base_estimator=svr_reg,n_estimators=100,random_state=rand_seed)\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=100,random_state=rand_seed)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(base_estimator=log_cf,random_state=rand_seed)\n",
    "gb_clf = GradientBoostingClassifier(random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Adaboost Regressor :  8.095924790351798\n",
      "MAE of Gradient Boosting Regressor :  7.933886043908278\n",
      "\n",
      "\n",
      "Accuracy of Adaboost Classifier :  83.0\n",
      "Accuracy of Gradient Boosting Classifier :  79.0\n"
     ]
    }
   ],
   "source": [
    "x_train,x_val,y_train,y_val = split_data(df,target_name='age_yrs')\n",
    "\n",
    "ada_reg.fit(x_train,y_train)\n",
    "gb_reg.fit(x_train,y_train)\n",
    "\n",
    "print('MAE of Adaboost Regressor : ', get_reg(ada_reg.predict(x_val),y_val))\n",
    "print('MAE of Gradient Boosting Regressor : ', get_reg(gb_reg.predict(x_val),y_val))\n",
    "\n",
    "x_train,x_val,y_train,y_val = split_data(df,target_name='bad_credit')\n",
    "\n",
    "ada_clf.fit(x_train,y_train)\n",
    "gb_clf.fit(x_train,y_train)\n",
    "\n",
    "print('\\n\\nAccuracy of Adaboost Classifier : ', get_acc(ada_clf.predict(x_val),y_val))\n",
    "print('Accuracy of Gradient Boosting Classifier : ', get_acc(gb_clf.predict(x_val),y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "First Level Learners > Use predictions from base learners to create new training data > Feed the new training data into another algo called meta-learner.\n",
    "\n",
    "## Procedure\n",
    "1. Split total training set into two disjoint sets - Training / Test\n",
    "2. Train several base models on first part \n",
    "3. Test base models on second part\n",
    "4. Use predictions from step 3 as inputs and correct responses as o/p to train a higher lever learner which is also called meta-learner.\n",
    "\n",
    "\n",
    "<img src='https://miro.medium.com/max/1318/1*9uCwjY5uRkRrX2VNST7R0w.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def stackingModel(base_models,meta_model,features,target,nfolds=10):\n",
    "    \n",
    "    # Split data into folds\n",
    "    kfold = KFold(n_splits=nfolds,shuffle=True,random_state=rand_seed)\n",
    "    \n",
    "    # Initialize an array to hold predictions\n",
    "    test_pred = np.zeros((features.shape[0],len(base_models)))\n",
    "    train_pred = np.zeros((features.shape[0],len(base_models)))\n",
    "\n",
    "    # Train base model or 1st level learners\n",
    "    for i, model in enumerate(base_models):\n",
    "        for train_index, test_index in kfold.split(features, target):\n",
    "            # Fit train data on model\n",
    "            model.fit(np.array(features)[train_index],np.array(target)[train_index])\n",
    "            \n",
    "            # Make predictions on the holdout data\n",
    "            y_pred = model.predict(np.array(features)[test_index])\n",
    "            \n",
    "            # Making predictions on the train data\n",
    "            t_pred = model.predict(np.array(features)[train_index])\n",
    "            \n",
    "            # Appending the predictions\n",
    "            test_pred[test_index,i] = y_pred\n",
    "            train_pred[train_index,i] = t_pred\n",
    "            \n",
    "            \n",
    "    # Now, let's train the meta-model\n",
    "    meta_model.fit(train_pred, target)\n",
    "    \n",
    "    # Make final predictions\n",
    "    final_pred = meta_model.predict(np.mean([test_pred],axis=0))\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Stacked Model :  7.109825798393478\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "\n",
    "target = df['age_yrs']\n",
    "data = df.drop('age_yrs',axis=1)\n",
    "data = standdata(data)\n",
    "\n",
    "# Base learners\n",
    "base_learners = [linear_reg,svr_reg,knn_reg]\n",
    "\n",
    "# Meta Learner\n",
    "meta_learner = svr_reg\n",
    "\n",
    "pred = stackingModel(base_learners,meta_learner, data, target)\n",
    "\n",
    "print('MAE of Stacked Model : ', get_reg(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Stacked Model :  76.6\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "\n",
    "target = df['bad_credit']\n",
    "data = df.drop('bad_credit',axis=1)\n",
    "data = standdata(data)\n",
    "\n",
    "# Base learners\n",
    "base_learners = [log_cf,knn_cf,svc_cf]\n",
    "\n",
    "# Meta Learner\n",
    "meta_learner = svc_cf\n",
    "\n",
    "pred = stackingModel(base_learners,meta_learner, data, target)\n",
    "\n",
    "print('Accuracy Score of Stacked Model : ', get_acc(pred,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectstack\n",
    "https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
